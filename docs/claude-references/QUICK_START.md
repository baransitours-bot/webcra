# Quick Start Guide - Immigration Platform

## ğŸ¯ All Issues Fixed!

âœ… **Database Viewer** - See everything in your database
âœ… **Custom Models** - Add any model you want
âœ… **Fixed Errors** - No more AttributeError or deprecation warnings
âœ… **Classifier CLI** - Works with database now
âœ… **Proper Indexing** - Clear workflow for data

---

## ğŸš€ Setup (First Time)

### 1. Create .env file with your API key

```bash
# Copy template
cp .env.example .env

# Edit and add your OpenRouter API key
# (Get FREE key from https://openrouter.ai/keys)
nano .env
```

Add this line:
```
OPENROUTER_API_KEY=sk-or-your-key-here
```

### 2. Start the app

```bash
streamlit run app.py
```

---

## ğŸ“Š View Your Database

### New Database Viewer Page (ğŸ’¾)

Go to **ğŸ’¾ Database** page in sidebar to see:

- **ğŸ“Š Overview** - Stats and table schemas
- **ğŸ•·ï¸ Crawled Pages** - All scraped pages (paginated, filterable)
- **ğŸ“‹ Visas** - Extracted visas (filter by country/category)
- **ğŸ‘¤ Clients** - Client profiles
- **âœ… Eligibility Checks** - Match results
- **âš™ï¸ Settings** - All config values and sources
- **ğŸ” Embeddings** - Semantic search indices

**Features:**
- Pagination (5-50 items per page)
- Filter by country, category
- Search visa types
- Export to JSON
- See where config comes from (.env vs database)

---

## ğŸ”§ Add Custom Models

### Settings Page (âš™ï¸)

1. Go to **âš™ï¸ Settings** page
2. Tab 2: Edit Settings
3. Check **"Use custom model"**
4. Enter any model name:
   - `google/gemini-pro`
   - `anthropic/claude-3.5-sonnet`
   - `openai/gpt-4o`
   - Any model from your provider
5. Click **Save**

**Predefined models available:**
- OpenRouter: `google/gemini-2.0-flash-001:free`, `meta-llama/llama-3.2-3b-instruct:free`, `anthropic/claude-3.5-sonnet`
- OpenAI: `gpt-4o-mini`, `gpt-4o`, `gpt-4-turbo`

---

## ğŸ“‹ Complete Workflow

### Step 1: Crawl Pages

**Option A: Use UI** (Recommended)
```bash
streamlit run app.py
# â†’ ğŸ•·ï¸ Crawler page
# â†’ Configure countries and settings
# â†’ Click "Start Crawling"
```

**Option B: Use CLI**
```bash
python main.py crawl --all
# OR
python main.py crawl --country canada
```

**Check results:**
- Go to ğŸ’¾ Database page â†’ Crawled Pages tab
- Or run: `python scripts/check_database.py`

---

### Step 2: Extract Visas

**Option A: Use UI** (Recommended)
```bash
streamlit run app.py
# â†’ ğŸ“Š Classifier page
# â†’ Select LLM provider (needs API key)
# â†’ Click "Start Classification"
```

**Option B: Use CLI**
```bash
python main.py classify --all
# OR
python main.py classify --country canada
```

**Check results:**
- Go to ğŸ’¾ Database page â†’ Visas tab
- Filter by country, category
- Export to JSON if needed

---

### Step 3: Create Embeddings (Optional)

For semantic search:

```bash
python scripts/index_embeddings.py
```

This creates vector embeddings for all visas.

**Check results:**
- Go to ğŸ’¾ Database page â†’ Embeddings tab
- Or run: `python scripts/search_semantic.py`

---

### Step 4: Test Semantic Search

```bash
python scripts/search_semantic.py
```

Enter natural language queries:
- "work visa for software engineers"
- "student visa for masters degree"
- "family visa for spouse"

---

## ğŸ” Check System Status

### Option 1: Home Page

Open app and look at banner:
- âœ… Green = System ready with API key
- âš ï¸ Yellow = No API key (limited features)

### Option 2: Database Viewer

Go to **ğŸ’¾ Database** â†’ **ğŸ“Š Overview** tab:
- See counts for everything
- Check table schemas
- View database file size

### Option 3: Settings Page

Go to **âš™ï¸ Settings** â†’ **Tab 1: Current Settings**:
- See all active settings
- Check source (ğŸŒ .env, ğŸ’¾ Database, ğŸ“„ YAML)
- Verify API key status

### Option 4: Run System Test

```bash
python scripts/test_system.py
```

Shows detailed status of all components.

---

## ğŸ—‚ï¸ View Data by Country

### In Database Viewer:

1. Go to **ğŸ’¾ Database** page
2. Select tab: **ğŸ•·ï¸ Crawled Pages** or **ğŸ“‹ Visas**
3. Use **"Filter by Country"** dropdown
4. Select your country
5. Use pagination to browse

**Export:**
- Click "Export as JSON" button
- Download filtered data

---

## âš™ï¸ Configuration Sources

Settings load in this priority:

1. **ğŸŒ .env file** (HIGHEST)
   - For API keys and secrets
   - Not committed to git

2. **ğŸ’¾ Database** (MEDIUM)
   - For user preferences
   - Editable via Settings UI

3. **ğŸ“„ YAML files** (LOWEST)
   - For service defaults
   - Version controlled

**To see where each setting comes from:**
- Go to ğŸ’¾ Database â†’ Settings tab
- Check the "Source" column

---

## ğŸ› Troubleshooting

### "No visas found in database"

**Cause:** You haven't run the Classifier yet

**Fix:**
1. Check you have crawled pages: Go to ğŸ’¾ Database â†’ Crawled Pages
2. If no pages: Run Crawler first
3. If have pages: Run Classifier (UI or CLI)

---

### "OpenRouter API key not found"

**Cause:** No API key configured

**Fix (Easy - Use UI):**
1. Go to âš™ï¸ Settings page
2. Tab 3: Environment (.env)
3. API Key Quick Setup section
4. Paste your OpenRouter key
5. Click Save
6. Restart app

**Fix (Manual - Use .env):**
```bash
echo "OPENROUTER_API_KEY=sk-or-your-key" >> .env
streamlit run app.py
```

Get FREE key: https://openrouter.ai/keys

---

### "AttributeError: 'DataStore' object has no attribute"

**Cause:** Old code trying to use JSON files instead of database

**Fix:** âœ… Already fixed! The classifier now uses Database.

If you still see this:
1. Pull latest code: `git pull`
2. Restart app

---

### Deprecation warning: "use_container_width"

**Fix:** âœ… Already fixed! Changed to `width='stretch'`

---

### "LLM features are disabled"

**Cause:** System working in fallback mode (no API key)

**What works without API key:**
- âœ… Crawler (web scraping)
- âœ… Pattern-based extraction (limited)
- âœ… Database viewing
- âœ… Settings management

**What needs API key:**
- âŒ LLM-powered visa extraction
- âŒ AI Assistant chat
- âŒ Intelligent requirement parsing

**Fix:** Add API key (see above)

---

## ğŸ“š Useful Commands

### View Database:
```bash
# In UI
streamlit run app.py â†’ ğŸ’¾ Database page

# In CLI
python scripts/check_database.py
python scripts/query_database.py
```

### Export Data:
```bash
# In UI: ğŸ’¾ Database page â†’ Export buttons

# In CLI
python scripts/query_database.py
# Select option to export
```

### Test System:
```bash
python scripts/test_system.py
python test_config_lifecycle.py
```

### Check Semantic Search:
```bash
python scripts/search_semantic.py
```

### Verify API Key:
```bash
# Check if .env exists
cat .env | grep OPENROUTER_API_KEY

# Or check in UI
streamlit run app.py â†’ âš™ï¸ Settings â†’ Tab 1
```

---

## ğŸ¨ UI Pages Overview

| Page | Icon | Purpose |
|------|------|---------|
| Home | ğŸŒ | Status overview, quick start |
| Crawler | ğŸ•·ï¸ | Scrape government websites |
| Classifier | ğŸ“Š | Extract visa data from pages |
| Matcher | ğŸ” | Check eligibility (coming soon) |
| Assistant | ğŸ’¬ | AI chat (coming soon) |
| Settings | âš™ï¸ | Configure API keys, models, etc. |
| **Database** | **ğŸ’¾** | **View all data (NEW!)** |

---

## ğŸ’¡ Pro Tips

1. **Always check Database Viewer first** to see what data you have
2. **Use pagination** for large datasets (set to 10-20 items)
3. **Filter by country** to focus on specific data
4. **Export to JSON** before making big changes
5. **Check Settings â†’ Tab 1** to see active configuration
6. **Use custom models** for better results (if you have access)
7. **Run embeddings after classification** for semantic search

---

## ğŸ¯ Next Steps

1. **Set API key** (if not done)
2. **View Database** to see what you have
3. **Crawl pages** for countries you need
4. **Classify visas** to extract structured data
5. **Create embeddings** for semantic search
6. **Use Database Viewer** to explore results

---

## ğŸ“– Documentation

- **Complete Guide:** `CONFIGURATION_LIFECYCLE.md`
- **Config Setup:** `CONFIG_GUIDE.md`
- **Scripts:** `scripts/README.md`
- **System Overview:** `SYSTEM.md`

---

## âœ… Summary

All issues fixed:
- âœ… Database visibility (new Database Viewer page)
- âœ… Custom models (Settings page)
- âœ… Classifier CLI (uses Database now)
- âœ… Streamlit warnings (deprecated params fixed)
- âœ… Clear error messages (actionable fixes)
- âœ… Paginated tables (5-50 items per page)
- âœ… Export functionality (JSON format)
- âœ… Config transparency (see sources)

**Everything is working! Start with the Database Viewer to see what you have! ğŸ’¾**
